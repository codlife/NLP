# NLP
1. 全面解析RNN,LSTM,Seq2Seq,Attention注意力机制 - CristianoC的文章 - 知乎 https://zhuanlan.zhihu.com/p/135970560
2. Attention用于NLP的一些小结 - susht的文章 - 知乎 https://zhuanlan.zhihu.com/p/35739040


# ML
1.简单的交叉熵损失函数，你真的懂了吗？ - 红色石头的文章 - 知乎 https://zhuanlan.zhihu.com/p/38241764
